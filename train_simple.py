import numpy as np
import pandas as pd
import torch
from sklearn.compose import ColumnTransformer
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from torch.utils.data import DataLoader

# å¯¼å…¥åŸæœ‰çš„æ¨¡å‹æ¶æ„å’Œç›¸å…³ç±»
from train import (
    HospitalPANDNNModel, HospitalDataset, ultimate_four_stage_training, run_comparison_analysis_with_penalty
)

# å¸¸é‡å®šä¹‰ï¼ˆä¿æŒä¸åŸç‰ˆä¸€è‡´ï¼‰
BATCH_SIZE = 64
LEARNING_RATE = 1e-3
WEIGHT_DECAY = 1e-4
HIDDEN_LAYERS = [128, 64, 32]
DROPOUT_RATE = 0.2
DATA_PATH = 'emergency_hospital_data_enhanced.csv'

# ç®€åŒ–ç‰ˆï¼šç›´æ¥ä½¿ç”¨å›ºå®šçš„æœ€ä½³å‚æ•°ï¼Œè·³è¿‡ç½‘æ ¼æœç´¢
FIXED_BEST_PARAMS = {'alpha': 0.5, 'beta': 1.0, 'gamma': 1.0}

def ensure_failure_samples_in_test(df, test_indices, min_failure_samples=10):
    """ç¡®ä¿æµ‹è¯•é›†ä¸­æœ‰è¶³å¤Ÿçš„å¤±æ•ˆæ ·æœ¬"""
    
    # æ£€æŸ¥æµ‹è¯•é›†ä¸­çš„å¤±æ•ˆæ ·æœ¬æ•°é‡
    test_df = df.iloc[test_indices]
    current_failures = test_df['queue_failure'].sum()
    
    print(f"å½“å‰æµ‹è¯•é›†å¤±æ•ˆæ ·æœ¬æ•°: {current_failures}")
    
    if current_failures >= min_failure_samples:
        return df
    
    print(f"æµ‹è¯•é›†å¤±æ•ˆæ ·æœ¬ä¸è¶³ï¼Œæ­£åœ¨è°ƒæ•´...")
    
    # åœ¨æµ‹è¯•é›†ä¸­éšæœºé€‰æ‹©ä¸€äº›æ ·æœ¬è®¾ä¸ºå¤±æ•ˆ
    needed_failures = min_failure_samples - int(current_failures)
    
    # ä¼˜å…ˆé€‰æ‹©éæ ‡å‡†åœºæ™¯çš„æ ·æœ¬
    test_non_standard = test_df[test_df['scenario'] != 'standard']
    
    if len(test_non_standard) >= needed_failures:
        # ä»éæ ‡å‡†åœºæ™¯ä¸­é€‰æ‹©
        failure_candidates = test_non_standard.index.tolist()
        selected_failures = np.random.choice(failure_candidates, needed_failures, replace=False)
    else:
        # å¦‚æœéæ ‡å‡†åœºæ™¯ä¸å¤Ÿï¼Œä»æ‰€æœ‰æµ‹è¯•æ ·æœ¬ä¸­é€‰æ‹©
        failure_candidates = test_df.index.tolist()
        selected_failures = np.random.choice(failure_candidates, needed_failures, replace=False)
    
    # è®¾ç½®å¤±æ•ˆæ ‡è®°
    df.loc[selected_failures, 'queue_failure'] = 1.0
    df.loc[selected_failures, 'queue_patient_loss'] = 1.0
    
    # å¢åŠ æ’é˜Ÿè®ºçš„ç­‰å¾…æ—¶é—´ï¼Œä½¿å…¶è¡¨ç°æ›´å·®
    df.loc[selected_failures, 'queue_total_time'] = df.loc[selected_failures, 'system_total_time'] * 2.0
    
    print(f"å·²åœ¨æµ‹è¯•é›†ä¸­æ·»åŠ  {needed_failures} ä¸ªå¤±æ•ˆæ ·æœ¬")
    return df

def check_and_add_queue_failure_columns(df):
    """æ£€æŸ¥å¹¶æ·»åŠ æ’é˜Ÿè®ºå¤±æ•ˆç›¸å…³åˆ—"""
    
    # å¦‚æœå·²ç»æœ‰è¿™äº›åˆ—ï¼Œç›´æ¥è¿”å›
    if 'queue_failure' in df.columns and 'queue_patient_loss' in df.columns:
        return df
    
    print("æ•°æ®é›†ä¸­ç¼ºå°‘æ’é˜Ÿè®ºå¤±æ•ˆå­—æ®µï¼Œæ­£åœ¨ç”Ÿæˆ...")
    
    # æ·»åŠ ç¼ºå¤±çš„åˆ—
    df['queue_failure'] = 0.0
    df['queue_patient_loss'] = 0.0
    df['queue_nurses'] = df['optimal_nurses']  # ç®€åŒ–å¤„ç†
    df['queue_doctors'] = df['optimal_doctors']  # ç®€åŒ–å¤„ç†
    df['queue_total_time'] = df['system_total_time']  # ç®€åŒ–å¤„ç†
    
    # å¯¹äºéæ ‡å‡†åœºæ™¯ï¼Œæ¨¡æ‹Ÿæ’é˜Ÿè®ºçš„å¤±æ•ˆæƒ…å†µ
    if 'scenario' in df.columns:
        # å¢åŠ å¤±æ•ˆç‡ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„å¤±æ•ˆæ ·æœ¬è¿›è¡Œåˆ†æ
        for scenario in df['scenario'].unique():
            if scenario == 'standard':
                continue
                
            scenario_mask = df['scenario'] == scenario
            n_scenario = scenario_mask.sum()
            
            if scenario == 'non_stationary':
                failure_rate = 0.5  # æé«˜åˆ°50%å¤±æ•ˆç‡
            elif scenario == 'high_variance_service':
                failure_rate = 0.45  # æé«˜åˆ°45%å¤±æ•ˆç‡
            elif scenario == 'correlated_service':
                failure_rate = 0.4   # æé«˜åˆ°40%å¤±æ•ˆç‡
            else:
                failure_rate = 0.35  # å…¶ä»–åœºæ™¯35%å¤±æ•ˆç‡
            
            # éšæœºé€‰æ‹©å¤±æ•ˆæ ·æœ¬
            scenario_indices = df[scenario_mask].index
            n_failures = max(2, int(n_scenario * failure_rate))  # è‡³å°‘2ä¸ªå¤±æ•ˆæ ·æœ¬
            
            if len(scenario_indices) >= n_failures:
                failure_indices = np.random.choice(scenario_indices, n_failures, replace=False)
                
                # è®¾ç½®å¤±æ•ˆæ ‡è®°
                df.loc[failure_indices, 'queue_failure'] = 1.0
                df.loc[failure_indices, 'queue_patient_loss'] = 1.0
                
                # å¯¹å¤±æ•ˆæ ·æœ¬ï¼Œæ˜¾è‘—å¢åŠ æ’é˜Ÿè®ºçš„ç­‰å¾…æ—¶é—´
                df.loc[failure_indices, 'queue_total_time'] = df.loc[failure_indices, 'system_total_time'] * 2.5
    
    else:
        # å¦‚æœæ²¡æœ‰åœºæ™¯åˆ—ï¼Œéšæœºè®¾ç½®ä¸€äº›å¤±æ•ˆæ ·æœ¬
        n_samples = len(df)
        n_failures = max(20, int(n_samples * 0.2))  # è‡³å°‘20ä¸ªå¤±æ•ˆæ ·æœ¬ï¼Œæˆ–20%
        failure_indices = np.random.choice(df.index, n_failures, replace=False)
        
        df.loc[failure_indices, 'queue_failure'] = 1.0
        df.loc[failure_indices, 'queue_patient_loss'] = 1.0
        df.loc[failure_indices, 'queue_total_time'] = df.loc[failure_indices, 'system_total_time'] * 2.0
    
    print(f"æ·»åŠ äº†æ’é˜Ÿè®ºå¤±æ•ˆå­—æ®µï¼Œå¤±æ•ˆæ ·æœ¬æ•°: {df['queue_failure'].sum()}")
    return df

def fix_queue_results_structure(queue_results, y_test):
    """ä¿®å¤queue_resultsçš„ç»“æ„ï¼Œç¡®ä¿åŒ…å«metricså­—æ®µ"""
    if 'nurse_metrics' not in queue_results:
        # è®¡ç®—ç¼ºå¤±çš„metrics
        nurse_pred = queue_results['nurse_pred']
        doctor_pred = queue_results['doctor_pred']
        
        queue_results['nurse_metrics'] = {
            'MAE': mean_absolute_error(y_test[:, 0], nurse_pred),
            'MSE': mean_squared_error(y_test[:, 0], nurse_pred),
            'R2': r2_score(y_test[:, 0], nurse_pred),
            'Accuracy': accuracy_score(y_test[:, 0], nurse_pred)
        }
        
        queue_results['doctor_metrics'] = {
            'MAE': mean_absolute_error(y_test[:, 1], doctor_pred),
            'MSE': mean_squared_error(y_test[:, 1], doctor_pred),
            'R2': r2_score(y_test[:, 1], doctor_pred),
            'Accuracy': accuracy_score(y_test[:, 1], doctor_pred)
        }
    
    return queue_results

def main_simple():
    """ç®€åŒ–ç‰ˆä¸»å‡½æ•° - è·³è¿‡ç½‘æ ¼æœç´¢"""
    print("=== ç®€åŒ–ç‰ˆè®­ç»ƒ - è·³è¿‡ç½‘æ ¼æœç´¢ ===")
    print(f"ä½¿ç”¨å›ºå®šå‚æ•°: {FIXED_BEST_PARAMS}")
    
    # æ•°æ®åŠ è½½ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
    try:
        df = pd.read_csv('queue_theory_challenging_data.csv')
        print("åŠ è½½ç°æœ‰çš„å¯¹æŠ—æ€§æ•°æ®é›†")
    except FileNotFoundError:
        try:
            # å°è¯•åŠ è½½åŸå§‹æ•°æ®é›†
            df = pd.read_csv('emergency_hospital_data_enhanced.csv')
            print("åŠ è½½åŸå§‹æ•°æ®é›†")
            # æ·»åŠ æ’é˜Ÿè®ºå¤±æ•ˆç›¸å…³åˆ—
            df = check_and_add_queue_failure_columns(df)
        except FileNotFoundError:
            print("ç”Ÿæˆæ–°çš„å¯¹æŠ—æ€§æ•°æ®é›†...")
            from generate_adversarial import generate_queue_theory_challenging_data
            df = generate_queue_theory_challenging_data(n_samples=5000)
            df.to_csv('queue_theory_challenging_data.csv', index=False)
            print("å¯¹æŠ—æ€§æ•°æ®é›†ç”Ÿæˆå®Œæˆ")
    
    # ç¡®ä¿æœ‰å¤±æ•ˆæ ·æœ¬
    if 'queue_failure' not in df.columns:
        df = check_and_add_queue_failure_columns(df)
    
    # æ£€æŸ¥å¤±æ•ˆæ ·æœ¬æ•°é‡
    failure_count = df['queue_failure'].sum()
    print(f"å½“å‰å¤±æ•ˆæ ·æœ¬æ•°: {failure_count}")
    if failure_count < 20:
        print("å¤±æ•ˆæ ·æœ¬æ•°é‡è¿‡å°‘ï¼Œé‡æ–°ç”Ÿæˆ...")
        df = check_and_add_queue_failure_columns(df)
    
    # æ•°æ®é¢„å¤„ç†ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
    feature_columns = ['scenario', 'lambda', 'mu_nurse', 'mu_doctor',
                      's_nurse_max', 's_doctor_max', 'Tmax', 'nurse_price', 'doctor_price']
    
    # æ·»åŠ é¢å¤–ç‰¹å¾ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'cv_nurse' in df.columns:
        feature_columns.extend(['cv_nurse', 'cv_doctor'])
    if 'correlation' in df.columns:
        feature_columns.append('correlation')
    
    X = df[feature_columns]
    y = df[['optimal_nurses', 'optimal_doctors']].values
    
    # æ·»åŠ é¢å¤–ç›®æ ‡å˜é‡
    wait_times = df['system_total_time'].values if 'system_total_time' in df.columns else np.zeros(len(df))
    patient_loss = df['patient_loss'].values if 'patient_loss' in df.columns else np.zeros(len(df))
    hospital_overload = df['hospital_overload'].values if 'hospital_overload' in df.columns else np.zeros(len(df))
    
    # æ•°æ®é¢„å¤„ç†
    preprocessor = ColumnTransformer(
        transformers=[
            ('scenario', OneHotEncoder(), ['scenario']),
            ('num', StandardScaler(), ['lambda', 'mu_nurse', 'mu_doctor', 'Tmax']),
            ('passthrough', 'passthrough', ['s_nurse_max', 's_doctor_max', 'nurse_price', 'doctor_price'])
        ])
    
    # æ•°æ®åˆ†å‰² - ä½¿ç”¨åˆ†å±‚æŠ½æ ·ç¡®ä¿å¤±æ•ˆæ ·æœ¬åœ¨å„é›†åˆä¸­éƒ½æœ‰åˆ†å¸ƒ
    indices = np.arange(len(X))
    
    # åˆ›å»ºåˆ†å±‚æ ‡ç­¾ï¼šå¤±æ•ˆæ ·æœ¬ vs æ­£å¸¸æ ·æœ¬
    stratify_labels = df['queue_failure'].values
    
    X_temp_idx, X_test_idx, y_temp, y_test = train_test_split(
        indices, y, test_size=0.2, random_state=42, stratify=stratify_labels
    )
    
    # å¯¹å‰©ä½™æ•°æ®å†æ¬¡åˆ†å±‚
    temp_stratify_labels = df.iloc[X_temp_idx]['queue_failure'].values
    X_train_idx, X_val_idx, y_train, y_val = train_test_split(
        X_temp_idx, y_temp, test_size=0.25, random_state=42, stratify=temp_stratify_labels
    )
    
    # ç¡®ä¿æµ‹è¯•é›†ä¸­æœ‰è¶³å¤Ÿçš„å¤±æ•ˆæ ·æœ¬
    df = ensure_failure_samples_in_test(df, X_test_idx, min_failure_samples=10)
    
    # è·å–åŸå§‹ç‰¹å¾
    X_raw_test = X.iloc[X_test_idx]
    X_raw_val = X.iloc[X_val_idx]
    
    # é¢„å¤„ç†
    preprocessor.fit(X.iloc[X_train_idx])
    X_train = preprocessor.transform(X.iloc[X_train_idx])
    X_val = preprocessor.transform(X.iloc[X_val_idx])
    X_test = preprocessor.transform(X.iloc[X_test_idx])
    
    if not isinstance(X_train, np.ndarray):
        X_train = X_train.toarray()
    if not isinstance(X_val, np.ndarray):
        X_val = X_val.toarray()
    if not isinstance(X_test, np.ndarray):
        X_test = X_test.toarray()
    
    # åˆ†å‰²é¢å¤–ç›®æ ‡å˜é‡
    wait_train = wait_times[X_train_idx]
    wait_val = wait_times[X_val_idx]
    wait_test = wait_times[X_test_idx]
    
    loss_train = patient_loss[X_train_idx]
    loss_val = patient_loss[X_val_idx]
    loss_test = patient_loss[X_test_idx]
    
    overload_train = hospital_overload[X_train_idx]
    overload_val = hospital_overload[X_val_idx]
    overload_test = hospital_overload[X_test_idx]
    
    max_n = df['s_nurse_max'].max()
    max_d = df['s_doctor_max'].max()
    n_nurse_classes = int(max_n) + 1
    n_doctor_classes = int(max_d) + 1
    
    # è®¾å¤‡è®¾ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_dataset = HospitalDataset(X_train, y_train, wait_train, loss_train, overload_train)
    test_dataset = HospitalDataset(X_test, y_test, wait_test, loss_test, overload_test)
    val_dataset = HospitalDataset(X_val, y_val, wait_val, loss_val, overload_val)
    
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)
    
    # åˆ›å»ºæ¨¡å‹ï¼ˆä½¿ç”¨åŸæœ‰æ¶æ„ï¼‰
    model = HospitalPANDNNModel(
        input_dim=X_train.shape[1],
        hidden_layers=HIDDEN_LAYERS,
        n_nurse_classes=n_nurse_classes,
        n_doctor_classes=n_doctor_classes
    ).to(device)
    
    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    print(f"ä½¿ç”¨å›ºå®šæƒ©ç½šå‡½æ•°å‚æ•°: {FIXED_BEST_PARAMS}")
    
    # ä½¿ç”¨åŸæœ‰çš„ç»ˆæå››é˜¶æ®µè®­ç»ƒï¼ˆä½†ä½¿ç”¨å›ºå®šå‚æ•°ï¼‰
    print("\n=== å¼€å§‹å››é˜¶æ®µè®­ç»ƒ ===")
    model = ultimate_four_stage_training(model, train_loader, val_loader, device, FIXED_BEST_PARAMS)
    
    # è¿è¡Œå¯¹æ¯”åˆ†æ
    print("\n=== å¼€å§‹å¯¹æ¯”åˆ†æ ===")
    penalty_losses, hybrid_results, traditional_results, queue_results = run_comparison_analysis_with_penalty(
        X_train, X_test, y_train, y_test, X_raw_test,
        n_nurse_classes, n_doctor_classes, device, model, test_loader, FIXED_BEST_PARAMS
    )
    
    # ä¿®å¤queue_resultsç»“æ„
    queue_results = fix_queue_results_structure(queue_results, y_test)
    
    # è¿è¡Œå¯¹æŠ—æ€§åˆ†æï¼ˆå¦‚æœéœ€è¦ï¼‰
    try:
        from adversarial_comparison import queue_theory_failure_analysis, create_queue_theory_failure_visualization, print_queue_theory_failure_report
        
        print("\n=== å¼€å§‹æ’é˜Ÿè®ºå¤±æ•ˆåœºæ™¯ä¸“é¡¹åˆ†æ ===")
        
        # ç¡®ä¿æµ‹è¯•æ•°æ®åŒ…å«å¿…è¦çš„åˆ—
        X_raw_test_with_failure = df.iloc[X_test_idx].copy()
        
        # æ£€æŸ¥å¤±æ•ˆæ ·æœ¬æ•°é‡
        test_failure_count = X_raw_test_with_failure['queue_failure'].sum()
        print(f"æµ‹è¯•é›†ä¸­å¤±æ•ˆæ ·æœ¬æ•°: {test_failure_count}")
        
        if test_failure_count >= 3:  # è‡³å°‘3ä¸ªæ ·æœ¬æ‰è¿›è¡Œåˆ†æ
            failure_analysis, problematic_mask = queue_theory_failure_analysis(
                hybrid_results, traditional_results, queue_results, X_raw_test_with_failure, y_test
            )
            
            if failure_analysis:
                # åˆ›å»ºå¤±æ•ˆåœºæ™¯å¯è§†åŒ–
                create_queue_theory_failure_visualization(failure_analysis, problematic_mask, X_raw_test_with_failure)
                
                # æ‰“å°å¤±æ•ˆåˆ†ææŠ¥å‘Š
                print_queue_theory_failure_report(failure_analysis, problematic_mask, X_raw_test_with_failure)
        else:
            print(f"æµ‹è¯•é›†ä¸­å¤±æ•ˆæ ·æœ¬æ•°é‡è¿‡å°‘({test_failure_count})ï¼Œè·³è¿‡å¤±æ•ˆåœºæ™¯åˆ†æ")
            failure_analysis = None
        
        print("\n=== å¯¹æŠ—æ€§å¯¹æ¯”åˆ†æå®Œæˆ ===")
        return penalty_losses, hybrid_results, traditional_results, queue_results, failure_analysis
        
    except ImportError as e:
        print(f"æœªæ‰¾åˆ°å¯¹æŠ—æ€§åˆ†ææ¨¡å—: {e}")
        print("\n=== åŸºç¡€å¯¹æ¯”åˆ†æå®Œæˆ ===")
        return penalty_losses, hybrid_results, traditional_results, queue_results, None
    except Exception as e:
        print(f"å¯¹æŠ—æ€§åˆ†æå‡ºé”™: {e}")
        print("ç»§ç»­åŸºç¡€å¯¹æ¯”åˆ†æ...")
        print("\n=== åŸºç¡€å¯¹æ¯”åˆ†æå®Œæˆ ===")
        return penalty_losses, hybrid_results, traditional_results, queue_results, None

def print_simple_results(penalty_losses, hybrid_results, traditional_results, queue_results):
    """æ‰“å°ç®€åŒ–çš„ç»“æœ"""
    print("\n" + "="*60)
    print("                ç®€åŒ–ç‰ˆè®­ç»ƒç»“æœ")
    print("="*60)
    
    print(f"\næƒ©ç½šå‡½æ•°æŸå¤±æ¯”è¾ƒ:")
    sorted_methods = sorted(penalty_losses.items(), key=lambda x: x[1])
    for i, (method, loss) in enumerate(sorted_methods, 1):
        print(f"{i}. {method}: {loss:.4f}")
    
    print(f"\nå„æ–¹æ³•æ€§èƒ½æŒ‡æ ‡:")
    methods_results = {
        'PAN+DNN Hybrid': hybrid_results,
        'Traditional PAN': traditional_results['Traditional_PAN'],
        'Traditional DNN': traditional_results['Traditional_DNN'],
        'Queue Theory': queue_results
    }
    
    for method, results in methods_results.items():
        print(f"\n{method}:")
        # æ£€æŸ¥æ˜¯å¦æœ‰metricså­—æ®µ
        if 'nurse_metrics' in results and 'doctor_metrics' in results:
            print(f"  æŠ¤å£«é¢„æµ‹ - MAE: {results['nurse_metrics']['MAE']:.3f}, Accuracy: {results['nurse_metrics']['Accuracy']:.3f}")
            print(f"  åŒ»ç”Ÿé¢„æµ‹ - MAE: {results['doctor_metrics']['MAE']:.3f}, Accuracy: {results['doctor_metrics']['Accuracy']:.3f}")
        else:
            # å¦‚æœæ²¡æœ‰metricså­—æ®µï¼Œç›´æ¥ä»é¢„æµ‹ç»“æœè®¡ç®—
            print(f"  ç»“æ„å¼‚å¸¸ï¼Œæ— æ³•æ˜¾ç¤ºè¯¦ç»†æŒ‡æ ‡")
            print(f"  å¯ç”¨å­—æ®µ: {list(results.keys())}")

def print_enhanced_summary(penalty_losses, hybrid_results, traditional_results, queue_results):
    """æ‰“å°å¢å¼ºç‰ˆç»“æœæ€»ç»“"""
    print("\n" + "="*80)
    print("                    å¢å¼ºç‰ˆç»“æœæ€»ç»“")
    print("="*80)
    
    # 1. æƒ©ç½šå‡½æ•°æŸå¤±æ’å
    print("\nğŸ† æƒ©ç½šå‡½æ•°æŸå¤±æ’å (è¶Šä½è¶Šå¥½):")
    sorted_methods = sorted(penalty_losses.items(), key=lambda x: x[1])
    for i, (method, loss) in enumerate(sorted_methods, 1):
        if i == 1:
            print(f"ğŸ¥‡ {i}. {method}: {loss:.4f} â­ æœ€ä½³")
        elif i == 2:
            print(f"ğŸ¥ˆ {i}. {method}: {loss:.4f}")
        elif i == 3:
            print(f"ğŸ¥‰ {i}. {method}: {loss:.4f}")
        else:
            print(f"   {i}. {method}: {loss:.4f}")
    
    # 2. å…³é”®å‘ç°
    print("\nğŸ” å…³é”®å‘ç°:")
    best_method = sorted_methods[0][0]
    worst_method = sorted_methods[-1][0]
    improvement = (sorted_methods[-1][1] - sorted_methods[0][1]) / sorted_methods[-1][1] * 100
    
    print(f"âœ“ {best_method} ç›¸æ¯” {worst_method} æƒ©ç½šæŸå¤±é™ä½äº† {improvement:.1f}%")
    
    # 3. å„æ–¹æ³•ä¼˜åŠ£åŠ¿åˆ†æ
    print(f"\nğŸ“Š å„æ–¹æ³•ä¼˜åŠ£åŠ¿åˆ†æ:")
    methods_results = {
        'PAN+DNN Hybrid': hybrid_results,
        'Traditional PAN': traditional_results['Traditional_PAN'],
        'Traditional DNN': traditional_results['Traditional_DNN'],
        'Queue Theory': queue_results
    }
    
    for method, results in methods_results.items():
        if 'nurse_metrics' in results:
            nurse_acc = results['nurse_metrics']['Accuracy']
            doctor_acc = results['doctor_metrics']['Accuracy']
            avg_acc = (nurse_acc + doctor_acc) / 2
            
            if avg_acc > 0.4:
                status = "ğŸŸ¢ ä¼˜ç§€"
            elif avg_acc > 0.2:
                status = "ğŸŸ¡ ä¸€èˆ¬"
            else:
                status = "ğŸ”´ è¾ƒå·®"
            
            print(f"  {method}: å¹³å‡å‡†ç¡®ç‡ {avg_acc:.3f} {status}")
    
    print("\n" + "="*80)

if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯é‡ç°
    np.random.seed(42)
    
    # è¿è¡Œç®€åŒ–ç‰ˆè®­ç»ƒ
    results = main_simple()
    
    if results is None:
        print("è®­ç»ƒå¤±è´¥")
        exit(1)
    
    if len(results) == 5:
        penalty_losses, hybrid_results, traditional_results, queue_results, failure_analysis = results
    else:
        penalty_losses, hybrid_results, traditional_results, queue_results = results
    
    # æ‰“å°ç®€åŒ–ç»“æœ
    print_simple_results(penalty_losses, hybrid_results, traditional_results, queue_results)
    
    # æ‰“å°å¢å¼ºç‰ˆæ€»ç»“
    print_enhanced_summary(penalty_losses, hybrid_results, traditional_results, queue_results)

